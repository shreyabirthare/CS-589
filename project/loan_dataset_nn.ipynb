{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_df = pd.read_csv('datasets/loan.csv', sep=',')  # 8 categorical attributes, 4 numerical attributes, and a Loan ID attribute Loan_Status - target\n",
    "loan_df.head() \n",
    "\n",
    "loan_df.rename(columns={'Loan_Status': 'target'}, inplace=True)\n",
    "column = loan_df.pop('target')\n",
    "loan_df.insert(len(loan_df.columns), 'target', column)\n",
    "loan_df.drop(['Loan_ID'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_of_col = {\n",
    "    'Gender': 0,\n",
    "    'Married': 0,\n",
    "    'Dependents': 0,\n",
    "    'Education': 0,\n",
    "    'Self_Employed': 0,\n",
    "    'ApplicantIncome': 1,\n",
    "    'CoapplicantIncome': 1, \n",
    "    'LoanAmount': 1,\n",
    "    'Loan_Amount_Term': 1,\n",
    "    'Credit_History': 0,\n",
    "    'Property_Area': 0, \n",
    "    'target': 0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_normalize = []\n",
    "to_encode = []\n",
    "for col in loan_df.columns:\n",
    "    if(type_of_col[col]):\n",
    "        to_normalize.append(col)\n",
    "    else:\n",
    "        to_encode.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_loan_df = normalise(loan_df, to_normalize)\n",
    "encoded_loan_df = encode_one_hot(norm_loan_df, to_encode)\n",
    "encoded_col_names = encoded_loan_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smaller_dfs = distribute_records(norm_loan_df, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_loan_df['target'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def arch_arr(input, output):\n",
    "    architectures = [\n",
    "        [input, 13, output],\n",
    "        [input, 13, output],\n",
    "        [input, 8, 9, output],\n",
    "        [input, 8, 9, 5, output],\n",
    "        [input, 8, 9, 5, output],\n",
    "        [input, 12, 18, 13, 15, output],\n",
    "    ]\n",
    "    return architectures\n",
    "\n",
    "\n",
    "architectures = arch_arr(22, 2)\n",
    "learning_rate = 0.1\n",
    "regularization_vals = [0, 0.1, 0,0, 0.1,0]\n",
    "\n",
    "idx = 0\n",
    "\n",
    "f1_score_matrix = np.zeros((10, len(architectures)))\n",
    "accuracy_matrix = np.zeros((10, len(architectures)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for architecture in architectures:      \n",
    "    regularization_param = regularization_vals[idx]\n",
    "    test_accuracy_across_folds = []\n",
    "    for fold in range(0,10):\n",
    "        weights = initialize_weights_minustoplus(architecture)\n",
    "        gradients = [np.zeros_like(theta) for theta in weights] \n",
    "        test_df = smaller_dfs[fold]\n",
    "        train_df = pd.concat(smaller_dfs[:fold] + smaller_dfs[fold+1:])\n",
    "        test_df.reset_index(inplace=True, drop=True)\n",
    "        train_df.reset_index(inplace=True, drop=True)\n",
    "        \n",
    "        test_df = encode_one_hot(test_df, to_encode)\n",
    "        test_df = correct_encoding(test_df, encoded_col_names)\n",
    "        \n",
    "        train_df = encode_one_hot(train_df,to_encode)\n",
    "        train_df = correct_encoding(train_df, encoded_col_names)\n",
    "\n",
    "        x_cols_tr = train_df.columns[:architecture[0]]\n",
    "        y_cols_tr = train_df.columns[-architecture[-1]:]\n",
    "\n",
    "        x_train = train_df[x_cols_tr].values\n",
    "        y_train = train_df[y_cols_tr].values\n",
    "\n",
    "        x_cols_ts = test_df.columns[:architecture[0]]\n",
    "        y_cols_ts = test_df.columns[-architecture[-1]:]\n",
    "\n",
    "        x_test = test_df[x_cols_ts].values\n",
    "        y_test = test_df[y_cols_ts].values\n",
    "\n",
    "        cost_before = calculate_cost(x_train, y_train, weights, regularization_param)\n",
    "\n",
    "        for i in range(500):\n",
    "            weights = backpropagation(x_train, y_train, architecture, weights, learning_rate, regularization_param)\n",
    "            cost_itr = calculate_cost(x_train, y_train, weights, regularization_param)\n",
    "\n",
    "        cost_after_forward_pass = calculate_cost(x_train, y_train, weights, regularization_param)\n",
    "\n",
    "        tr_results = []\n",
    "        for i in range(len(x_train)):\n",
    "            pred_i = forward_pass(x_train[i], weights)\n",
    "            max_index_pred = np.argmax(pred_i)\n",
    "            max_index_true = np.argmax(y_train[i])\n",
    "            tr_results.append((max_index_pred+1, max_index_true+1))\n",
    "        train_results = pd.DataFrame(tr_results, columns=['predicted_target', 'target'])\n",
    "        train_accuracy, train_f1 = calculate_performance(train_results)\n",
    "        \n",
    "        ts_results = []\n",
    "        for i in range(len(x_test)):\n",
    "            pred_i = forward_pass(x_test[i], weights)\n",
    "            max_index_pred = np.argmax(pred_i)\n",
    "            max_index_true = np.argmax(y_test[i])\n",
    "            ts_results.append((max_index_pred+1, max_index_true+1))\n",
    "        test_results = pd.DataFrame(ts_results, columns=['predicted_target', 'target'])\n",
    "        test_accuracy, test_f1 = calculate_performance(test_results)\n",
    "        test_accuracy_across_folds.append(test_accuracy)\n",
    "        accuracy_matrix[fold, idx]  = test_accuracy\n",
    "        f1_score_matrix[fold, idx] = test_f1\n",
    "    idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_accuracy = np.mean(accuracy_matrix, axis=0)\n",
    "average_f1 = np.mean(f1_score_matrix, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, arch in enumerate(architectures):\n",
    "    description = f\"Architecture {i+1}: \"\n",
    "    description += f\"Layers: {arch[:]}, Regularization Param: {regularization_vals[i]}\"\n",
    "    print(description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(accuracy_matrix, columns=[f'Architecture {i+1}' for i in range(len(architectures))])\n",
    "\n",
    "# Calculate mean for each architecture and add as last row\n",
    "mean_row = df.mean(axis=0)\n",
    "mean_row.name = 'Mean'\n",
    "df = pd.concat([df, mean_row.to_frame().T])\n",
    "\n",
    "# Display DataFrame\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(f1_score_matrix, columns=[f'Architecture {i+1}' for i in range(len(architectures))])\n",
    "\n",
    "# Calculate mean for each architecture and add as last row\n",
    "mean_row = df.mean(axis=0)\n",
    "mean_row.name = 'Mean'\n",
    "df = pd.concat([df, mean_row.to_frame().T])\n",
    "\n",
    "# Display DataFrame\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### learnign curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_loan_df = normalise(loan_df, to_normalize)\n",
    "encoded_loan_df = encode_one_hot(norm_loan_df, to_encode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.1\n",
    "regularization_param = 0\n",
    "architecture = [22, 13, 2]\n",
    "\n",
    "weights = initialize_weights_minustoplus(architecture)\n",
    "\n",
    "\n",
    "\n",
    "x_cols = encoded_loan_df.columns[:architecture[0]]\n",
    "y_cols = encoded_loan_df.columns[-architecture[-1]:]\n",
    "\n",
    "x = encoded_loan_df[x_cols].values\n",
    "y = encoded_loan_df[y_cols].values\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=42)\n",
    "\n",
    "\n",
    "cost_j_on_test_set = []\n",
    "iterations_val = []\n",
    "\n",
    "\n",
    "# Initialize weights and gradients\n",
    "original_weights = initialize_weights_minustoplus(architecture)\n",
    "original_gradients = [np.zeros_like(theta) for theta in weights]\n",
    "\n",
    "# Loop over the range of indices\n",
    "for offset in range(0,901, 120):\n",
    "    # Set weights and gradients to original values\n",
    "    weights = original_weights\n",
    "    gradients = original_gradients\n",
    "    \n",
    "    # Iterate over the data in batches of size 20\n",
    "    for idx in range(10, len(x_train), 20):\n",
    "        # Perform backpropagation on a subset of the training data\n",
    "        weights = backpropagation(x_train[:idx], y_train[:idx], architecture, weights, learning_rate, regularization_param)\n",
    "    \n",
    "    # Calculate cost on the test set\n",
    "    cost_itr = calculate_cost(x_test, y_test, weights, regularization_param)\n",
    "    \n",
    "    # Append cost and iteration values to lists\n",
    "    cost_j_on_test_set.append(cost_itr)\n",
    "    iterations_val.append(offset + idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(iterations_val, cost_j_on_test_set, marker='o', linestyle='-')\n",
    "plt.title('Learning Curve')\n",
    "plt.xlabel('Number of Training Examples')\n",
    "plt.ylabel('Cost Function J value')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
