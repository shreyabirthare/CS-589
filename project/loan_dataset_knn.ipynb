{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_df = pd.read_csv('datasets/loan.csv', sep=',')  # 8 categorical attributes, 4 numerical attributes, and a Loan ID attribute Loan_Status - target\n",
    "loan_df.head() \n",
    "\n",
    "loan_df.rename(columns={'Loan_Status': 'target'}, inplace=True)\n",
    "column = loan_df.pop('target')\n",
    "loan_df.insert(len(loan_df.columns), 'target', column)\n",
    "loan_df.drop(['Loan_ID'], axis=1, inplace=True)\n",
    "\n",
    "# Loan_ID is just an identifier and is not very useful so can be ignored while predictions\n",
    "# different algos that I can use here: KNN, decision tree, naive bayes, random forest, neural networks,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_of_col = {\n",
    "    'Gender': 0,\n",
    "    'Married': 0,\n",
    "    'Dependents': 0,\n",
    "    'Education': 0,\n",
    "    'Self_Employed': 0,\n",
    "    'ApplicantIncome': 1,\n",
    "    'CoapplicantIncome': 1, \n",
    "    'LoanAmount': 1,\n",
    "    'Loan_Amount_Term': 1,\n",
    "    'Credit_History': 0,\n",
    "    'Property_Area': 0, \n",
    "    'target': 0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_df['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_normalize = []\n",
    "to_encode = []\n",
    "for col in loan_df.columns:\n",
    "    if col == 'target':\n",
    "        continue\n",
    "    if(type_of_col[col]):\n",
    "        to_normalize.append(col)\n",
    "    else:\n",
    "        to_encode.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_loan_df = normalise(loan_df, to_normalize)\n",
    "encoded_loan_df = encode_one_hot(norm_loan_df, to_encode)\n",
    "shuffled_df = shuffle_dt(encoded_loan_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smaller_dfs = distribute_records(encoded_loan_df, 10)\n",
    "max_k = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_test = []\n",
    "f1_train = []\n",
    "accuracies_test = []\n",
    "accuracies_train = []\n",
    "for k_val in range(1, 52, max_k):\n",
    "    print('k_val: ', k_val)\n",
    "    acc_ts = []\n",
    "    f1_ts = []\n",
    "    acc_tr = []\n",
    "    f1_tr = []\n",
    "    for fold in range(0,10):\n",
    "        print('Fold: ', fold)\n",
    "        test_df = smaller_dfs[fold]\n",
    "        train_df = pd.concat(smaller_dfs[:fold] + smaller_dfs[fold+1:])\n",
    "        #print('Fold: ', fold, 'Length of train and test: ', len(train_df), len(test_df))\n",
    "        test_df.reset_index(inplace=True, drop=True)\n",
    "        train_df.reset_index(inplace=True, drop=True)\n",
    "        acc, f1 = accuracy_on_test(train_df, test_df, k_val)\n",
    "        acctr, f1tr = accuracy_on_train(train_df, k_val)\n",
    "        acc_tr.append(acctr)\n",
    "        f1_tr.append(f1tr)\n",
    "        acc_ts.append(acc)\n",
    "        f1_ts.append(f1)\n",
    "    accuracies_test.append(acc_ts)\n",
    "    f1_test.append(f1_ts)\n",
    "    accuracies_train.append(acc_tr)\n",
    "    f1_train.append(f1_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "final_df_acc = pd.DataFrame()\n",
    "final_df_f1 = pd.DataFrame()\n",
    "final_df_acc_tr = pd.DataFrame()\n",
    "final_df_f1_tr = pd.DataFrame()\n",
    "k_values = []\n",
    "for i in range(1, 52, max_k):\n",
    "    k_values.append(i)\n",
    "\n",
    "for i, k_val in enumerate(k_values):\n",
    "    final_df_acc_tr[k_val] = accuracies_train[i]\n",
    "    final_df_f1_tr[k_val] = f1_train[i]\n",
    "    final_df_acc[k_val] = accuracies_test[i]\n",
    "    final_df_f1[k_val] = f1_test[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df_acc = final_df_acc.add_prefix('k_val_')\n",
    "final_df_f1 = final_df_f1.add_prefix('k_val_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_row = final_df_acc.mean(axis=0)\n",
    "mean_row.name = 'Mean'\n",
    "final_df_acc = pd.concat([final_df_acc, mean_row.to_frame().T])\n",
    "final_df_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_row = final_df_f1.mean(axis=0)\n",
    "mean_row.name = 'Mean'\n",
    "final_df_f1 = pd.concat([final_df_f1, mean_row.to_frame().T])\n",
    "final_df_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_accuracies = []\n",
    "\n",
    "for col in final_df_acc_tr.columns:\n",
    "  column_mean = final_df_acc_tr[col].mean()\n",
    "  train_accuracies.append(column_mean)\n",
    "\n",
    "k_values = list(range(1, 52, max_k))\n",
    "\n",
    "train_std_dev = []\n",
    "for col in final_df_acc_tr.columns:\n",
    "  column_std = final_df_acc_tr[col].std()\n",
    "  train_std_dev.append(column_std)\n",
    "\n",
    "plt.plot(k_values, train_accuracies, marker='o', linestyle='-')\n",
    "plt.errorbar(k_values, train_accuracies, yerr=train_std_dev, fmt='o', capsize=5)\n",
    "plt.xlabel('k values')\n",
    "plt.ylabel('Accuracies over training data')\n",
    "plt.title('Accuracy vs k values')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_accuracies = []\n",
    "\n",
    "for col in final_df_acc.columns:\n",
    "  column_mean = final_df_acc[col].mean()\n",
    "  test_accuracies.append(column_mean)\n",
    "\n",
    "k_values = list(range(1, 52, max_k))\n",
    "\n",
    "test_std_dev = []\n",
    "for col in final_df_acc.columns:\n",
    "  column_std = final_df_acc[col].std()\n",
    "  test_std_dev.append(column_std)\n",
    "\n",
    "plt.plot(k_values, test_accuracies, marker='o', linestyle='-')\n",
    "plt.errorbar(k_values, test_accuracies, yerr=test_std_dev, fmt='o', capsize=5)\n",
    "plt.xlabel('k values')\n",
    "plt.ylabel('Accuracies over testing data')\n",
    "plt.title('Accuracy vs k values')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
