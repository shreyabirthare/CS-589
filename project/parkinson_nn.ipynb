{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parki_df = pd.read_csv('datasets/parkinsons.csv', sep=',')  # 22 numerical attributes, diagnosis - target\n",
    "parki_df.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parki_df.rename(columns={'Diagnosis': 'target'}, inplace=True)\n",
    "column = parki_df.pop('target')\n",
    "parki_df.insert(len(parki_df.columns), 'target', column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_of_col = {\n",
    "    'MDVP:Fo(Hz)': 1,\n",
    "    'MDVP:Fhi(Hz)': 1,\n",
    "    'MDVP:Flo(Hz)': 1,\n",
    "    'MDVP:Jitter(%)': 1,\n",
    "    'MDVP:Jitter(Abs)': 1,\n",
    "    'MDVP:RAP': 1,\n",
    "    'MDVP:PPQ': 1,\n",
    "    'Jitter:DDP': 1,\n",
    "    'MDVP:Shimmer': 1,\n",
    "    'MDVP:Shimmer(dB)': 1,\n",
    "    'Shimmer:APQ3': 1,\n",
    "    'Shimmer:APQ5': 1,\n",
    "    'MDVP:APQ': 1,\n",
    "    'Shimmer:DDA': 1,\n",
    "    'NHR': 1,\n",
    "    'HNR': 1,\n",
    "    'RPDE': 1,\n",
    "    'DFA': 1,\n",
    "    'spread1': 1,\n",
    "    'spread2': 1,\n",
    "    'D2': 1,\n",
    "    'PPE': 1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_normalize = (parki_df.columns).to_list()\n",
    "to_normalize.remove('target')\n",
    "to_encode = ['target']\n",
    "normalised_df = normalise(parki_df, to_normalize)\n",
    "normalised_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_df = encode_one_hot(normalised_df, to_encode)\n",
    "encoded_col_names = encoded_df.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smaller_dfs = distribute_records(normalised_df, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalised_df['target'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def arch_arr(input, output):\n",
    "    architectures = [\n",
    "        [input, 15, output],\n",
    "        [input, 15, output],\n",
    "        [input, 8, 9, output],\n",
    "        [input, 8, 9, 5, output],\n",
    "        [input, 12, 18, 13, 15, output],\n",
    "    ]\n",
    "    return architectures\n",
    "\n",
    "\n",
    "architectures = arch_arr(22, 2)\n",
    "learning_rate = 0.1\n",
    "regularization_vals = [0,0.1, 0,0,0]\n",
    "\n",
    "idx = 0\n",
    "\n",
    "f1_score_matrix = np.zeros((10, len(architectures)))\n",
    "accuracy_matrix = np.zeros((10, len(architectures)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for architecture in architectures:      \n",
    "    regularization_param = regularization_vals[idx]\n",
    "    for fold in range(0,10):\n",
    "        weights = initialize_weights_minustoplus(architecture)\n",
    "        gradients = [np.zeros_like(theta) for theta in weights] \n",
    "        test_df = smaller_dfs[fold]\n",
    "        train_df = pd.concat(smaller_dfs[:fold] + smaller_dfs[fold+1:])\n",
    "        test_df.reset_index(inplace=True, drop=True)\n",
    "        train_df.reset_index(inplace=True, drop=True)\n",
    "        \n",
    "        test_df = encode_one_hot(test_df, to_encode)\n",
    "        test_df = correct_encoding(test_df, encoded_col_names)\n",
    "        \n",
    "        train_df = encode_one_hot(train_df,to_encode)\n",
    "        train_df = correct_encoding(train_df, encoded_col_names)\n",
    "\n",
    "        x_cols_tr = train_df.columns[:architecture[0]]\n",
    "        y_cols_tr = train_df.columns[-architecture[-1]:]\n",
    "\n",
    "        x_train = train_df[x_cols_tr].values\n",
    "        y_train = train_df[y_cols_tr].values\n",
    "\n",
    "        x_cols_ts = test_df.columns[:architecture[0]]\n",
    "        y_cols_ts = test_df.columns[-architecture[-1]:]\n",
    "\n",
    "        x_test = test_df[x_cols_ts].values\n",
    "        y_test = test_df[y_cols_ts].values\n",
    "\n",
    "        cost_before = calculate_cost(x_train, y_train, weights, regularization_param)\n",
    "\n",
    "        for i in range(500):\n",
    "            weights = backpropagation(x_train, y_train, architecture, weights, learning_rate, regularization_param)\n",
    "            cost_itr = calculate_cost(x_train, y_train, weights, regularization_param)\n",
    "\n",
    "        cost_after_forward_pass = calculate_cost(x_train, y_train, weights, regularization_param)\n",
    "\n",
    "        tr_results = []\n",
    "        for i in range(len(x_train)):\n",
    "            pred_i = forward_pass(x_train[i], weights)\n",
    "            max_index_pred = np.argmax(pred_i)\n",
    "            max_index_true = np.argmax(y_train[i])\n",
    "            tr_results.append((max_index_pred+1, max_index_true+1))\n",
    "        train_results = pd.DataFrame(tr_results, columns=['predicted_target', 'target'])\n",
    "        train_accuracy, train_f1 = calculate_performance(train_results)\n",
    "        \n",
    "        ts_results = []\n",
    "        for i in range(len(x_test)):\n",
    "            pred_i = forward_pass(x_test[i], weights)\n",
    "            max_index_pred = np.argmax(pred_i)\n",
    "            max_index_true = np.argmax(y_test[i])\n",
    "            ts_results.append((max_index_pred+1, max_index_true+1))\n",
    "        test_results = pd.DataFrame(ts_results, columns=['predicted_target', 'target'])\n",
    "        test_accuracy, test_f1 = calculate_performance(test_results)\n",
    "        accuracy_matrix[fold, idx]  = test_accuracy\n",
    "        f1_score_matrix[fold, idx] = test_f1\n",
    "    idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_accuracy = np.mean(accuracy_matrix, axis=0)\n",
    "average_f1 = np.mean(f1_score_matrix, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, arch in enumerate(architectures):\n",
    "    description = f\"Architecture {i+1}: \"\n",
    "    description += f\"Layers: {arch[:]}, Regularization Param: {regularization_vals[i]}\"\n",
    "    print(description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(accuracy_matrix, columns=[f'Architecture {i+1}' for i in range(len(architectures))])\n",
    "\n",
    "# Calculate mean for each architecture and add as last row\n",
    "mean_row = df.mean(axis=0)\n",
    "mean_row.name = 'Mean'\n",
    "df = pd.concat([df, mean_row.to_frame().T])\n",
    "\n",
    "# Display DataFrame\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(f1_score_matrix, columns=[f'Architecture {i+1}' for i in range(len(architectures))])\n",
    "\n",
    "# Calculate mean for each architecture and add as last row\n",
    "mean_row = df.mean(axis=0)\n",
    "mean_row.name = 'Mean'\n",
    "df = pd.concat([df, mean_row.to_frame().T])\n",
    "\n",
    "# Display DataFrame\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### learnign curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalised_df = normalise(parki_df, to_normalize)\n",
    "encoded_df = encode_one_hot(normalised_df, to_encode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.1\n",
    "regularization_param = 0\n",
    "architecture = [22, 8, 4, 2]\n",
    "\n",
    "weights = initialize_weights_minustoplus(architecture)\n",
    "\n",
    "\n",
    "x_cols = encoded_df.columns[:architecture[0]]\n",
    "y_cols = encoded_df.columns[-architecture[-1]:]\n",
    "\n",
    "x = encoded_df[x_cols].values\n",
    "y = encoded_df[y_cols].values\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=42)\n",
    "\n",
    "\n",
    "cost_j_on_test_set = []\n",
    "iterations_val = []\n",
    "\n",
    "\n",
    "# Initialize weights and gradients\n",
    "original_weights = initialize_weights_minustoplus(architecture)\n",
    "original_gradients = [np.zeros_like(theta) for theta in weights]\n",
    "\n",
    "\n",
    "weights = original_weights\n",
    "gradients = original_gradients\n",
    "\n",
    "offset = 150\n",
    "# Iterate over the data in batches of size 20\n",
    "for idx in range(10, len(x_train), 20):\n",
    "    # Perform backpropagation on a subset of the training data\n",
    "    weights = backpropagation(x_train[:idx], y_train[:idx], architecture, weights, learning_rate, regularization_param)\n",
    "\n",
    "# Calculate cost on the test set\n",
    "    cost_itr = calculate_cost(x_test, y_test, weights, regularization_param)\n",
    "    \n",
    "    # Append cost and iteration values to lists\n",
    "    cost_j_on_test_set.append(cost_itr)\n",
    "    iterations_val.append(idx)\n",
    "\n",
    "for idx in range(10, 70, 20):\n",
    "    \n",
    "    weights = backpropagation(x_train[:idx], y_train[:idx], architecture, weights, learning_rate, regularization_param)\n",
    "\n",
    "\n",
    "    cost_itr = calculate_cost(x_test, y_test, weights, regularization_param)\n",
    "\n",
    "    cost_j_on_test_set.append(cost_itr)\n",
    "    iterations_val.append(offset)\n",
    "    offset += 20\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(iterations_val, cost_j_on_test_set, marker='o', linestyle='-')\n",
    "plt.title('Learning Curve')\n",
    "plt.xlabel('Number of Training Examples')\n",
    "plt.ylabel('Cost Function J value')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
